### smj_data_prep.Rmd

# General Notes
This is where the code begins once you have completed the setup. This file performs the matching between the treatment and control companies. 

# File Requirements
data/cem_data/controls_for_cem_private_v2.xlsx
data/cem_data/controls_for_cem_public_v3.xlsx

# setup section
This section pulls the useful tables from the database. We really only use the companies table. The company financials ended up not being used. 

# dataset_prep section
This section creates the dataframes sub_X_2yr by pulling information on companies and reviews from the database (before_after_company_2yr). The sub_X_2yr dataframe contains two entries for each company that had a least X total reviews with X/2 reviews coming before the IPO. sub_10_2yr is the primary dataset we use, and it contains two entries for each company that had at least 5 reviews before AND after the IPO. The entries per company are split into two rows based on the reviews that came before or after the IPO (before_after column). 

# cem section
This section performs the coarsend exact matching. I am currently performing one-to-many matching between the companies that go public and the control companies. There are two sets of controls, private and public companies, though the only one currently used in the paper is private companies. Since the reviewers did not raise concerns about controlling against public comapnies, we do have the option to report those as additional robustness if the IV approach doesn't work out. 

The code itself was a real fun exercise in the poorly documented cem package. I tried to comment it well, but essentially what it is doing is matching the companies that went public with those that didn't on two digit SIC code, founding year, and number of employees.

In order to do this, two files need to be in the data/cem_data folder: controls_for_cem_public_v3.xlsx and controls_for_cem_private_v2.xlsx
Once these files are present, you should be able to execute this entire section. Take a look at:
head(control_private_match_10_rev[control_private_match_10_rev$strata == 26,]) 
This should give a sense for the matching. In strata 26, you should see that tamino corp and xbiotech corp were both matched to two private companies. 

As a final double check, you can also see if the sub_10_2yr dataframe is the right length. In both my old database and R file it is 388 rows. 

Once this matching is complete, we move over to Python to: 
1.) Assess the number of reviews in each of these matched private companies 
2.) Create a final sample of companies and reivews
3.) Perform the sentiment analysis on the final set of comapnies and reviews




### reivews_to_pandas.py

# General Notes
This is the first of two files you should need to use in Python. What it does is find the cases where the matched treatment and control companies have enough reivews in the -1/+2 year span around the treatement company's IPO date. When this happens, these reviews are then written to the data/reviews_processed folder. 

# File Requirements
data/review_data_raw/ipo_company_reviews_update_02_14_19.pickle
data/review_data_raw/nyse_and_nasdaq_reviews_update_02_14_19.pickle
data/review_data_raw/private_company_reviews_update_02_14_19.pickle

# get_control_reviews
This is the main function that will be used in this file. Everything else is either a helper function or no longer used. This function merges the raw reviews pulled in the scraping process with the matched treatement and control companies as indicated by CEM in R. Each step in this function is commented, but let me know if you have any questions. 

To actually run the function, just uncomment all of the get_control_review(...) functions at the bottom of the file and run via:
>> python reviews_to_pandas.py
After you do this, you should see files in the data/review_data_processed folder.


### sentiment_analyze.py

# General Notes
This is where the actual sentiment analysis happens. The processed reviews from reviews_to_pandas.py are pulled in, and we use VADER to analyze the sentiment of each sentence. The results are then saved to the psql database (becasue the files are very large and unweildy if we dump to excel). This relies heavily on the nltk package, and we will need to get the necessary data for it to operate. 

# File Requirements
*Should have been generated by reviews_to_pandas.py

# Downloading nltk data
Start python and import nltk. Then open the nltk downloader via the following commands.
>> python
>> import nltk
>> nltk.download()
This should open a GUI. Select to download "all". Once done, all the options should be green. 


# Topics
This is probably the most important thing in the code. Starting at line 392, you will see the topics that are used to map sentences and sentiment scores to the constructs we are trying to measure. If we want to smash a bunch of topics together, you just add it in here and the code should process it. For example, I went ahead and smashed all the previous topics into their higher grouping of distributive justic (DJ), procedural justice (PJ), and interactional justice (IJ). Whatever future modifications you want to make to the code will probably go through here.

The other important thing to note about the topics is that they contain the stemmed version of the text. If you want to add a word, check the Porter Stem first before doing anything. 
>> python
>> from nltk.stem import PorterStemmer
>> ps = PorterStemmer
>> ps.stem('culture') # outputs 'cultur'

# get_results(control, rev_limit)
This is the function that actually runs the code. It indicates whether to get calculate the sentiment scores for the private control companies, the public control companies, or the treatment companies (IPO companies). It will take a bit to run, especially for the first iteration where you have to tokenize the reviews. I recommend running the first three (which are currently uncommented) first. After those successfully run, you can run the rest. The results of the sentiment analysis are written to the psql database. We'll pull those into the R file to run the actual regressions. To run the code, simply uncomment the get_results(...) functions you want to run and use the code
>> python sentiment_analyze.py




### smj_analysis.Rmd

# General Notes


# File Requirements
N/A











